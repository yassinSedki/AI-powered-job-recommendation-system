{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ JobHunt Feature Engineering Pipeline\n",
    "\n",
    "This notebook provides a comprehensive demonstration of the JobHunt feature engineering pipeline.\n",
    "\n",
    "## üìã **What This Notebook Covers:**\n",
    "\n",
    "### üîß **Individual Module Testing:**\n",
    "- **Qualifications**: Classification into Bachelor/Master/PhD categories\n",
    "- **Work Types**: Standardization into Contract/Part-time/Internship/Full-time\n",
    "- **Experience**: Parsing text ranges into numerical min/max/mid values\n",
    "- **Salary**: Converting salary ranges into structured numerical features\n",
    "- **Text Processing**: Combining and cleaning role, job title, and skills\n",
    "\n",
    "### üèóÔ∏è **Complete Pipeline:**\n",
    "- Full `FeatureEngineeringPipeline` demonstration\n",
    "- Real dataset processing\n",
    "- Feature statistics and analysis\n",
    "- Data quality assessment\n",
    "\n",
    "### üìä **Analysis & Visualization:**\n",
    "- Feature distribution plots\n",
    "- Statistical summaries\n",
    "- Data completeness analysis\n",
    "- Export processed features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Standard libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('‚úÖ Standard libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/ai courses/JobHunt\n",
      "‚úÖ Added to Python path: /mnt/d/ai courses/JobHunt\n",
      "‚úÖ feature_engineering directory exists: False\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'feature_engineering'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m‚úÖ feature_engineering directory exists: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(ai_model_dir\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfeature_engineering\u001b[39m\u001b[33m\"\u001b[39m).exists()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Import the main pipeline and individual functions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfeature_engineering\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     22\u001b[39m     FeatureEngineeringPipeline,\n\u001b[32m     23\u001b[39m     classify_qualification,\n\u001b[32m     24\u001b[39m     process_qualifications,\n\u001b[32m     25\u001b[39m     standardize_work_type,\n\u001b[32m     26\u001b[39m     process_work_types,\n\u001b[32m     27\u001b[39m     parse_experience_range,\n\u001b[32m     28\u001b[39m     process_experience,\n\u001b[32m     29\u001b[39m     parse_salary_range,\n\u001b[32m     30\u001b[39m     process_salary,\n\u001b[32m     31\u001b[39m     clean_and_combine_text,\n\u001b[32m     32\u001b[39m     process_text_features\n\u001b[32m     33\u001b[39m )\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m‚úÖ Feature engineering modules imported successfully!\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'feature_engineering'"
     ]
    }
   ],
   "source": [
    "# Import feature engineering modules\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the project root (JobHunt) and ai_model directory\n",
    "current_dir = Path.cwd()\n",
    "print(current_dir)\n",
    "if current_dir.name == 'notebooks':\n",
    "    ai_model_dir = current_dir.parent  # this is ai_model\n",
    "else:\n",
    "    ai_model_dir = current_dir\n",
    "\n",
    "# Add ai_model directory to Python path\n",
    "if str(ai_model_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(ai_model_dir))\n",
    "\n",
    "print(f'‚úÖ Added to Python path: {ai_model_dir}')\n",
    "print(f'‚úÖ feature_engineering directory exists: {(ai_model_dir / \"feature_engineering\").exists()}')\n",
    "\n",
    "# Import the main pipeline and individual functions\n",
    "from feature_engineering import (\n",
    "    FeatureEngineeringPipeline,\n",
    "    classify_qualification,\n",
    "    process_qualifications,\n",
    "    standardize_work_type,\n",
    "    process_work_types,\n",
    "    parse_experience_range,\n",
    "    process_experience,\n",
    "    parse_salary_range,\n",
    "    process_salary,\n",
    "    clean_and_combine_text,\n",
    "    process_text_features\n",
    ")\n",
    "\n",
    "print('‚úÖ Feature engineering modules imported successfully!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_visualizations(df, qual_analysis, worktype_analysis, cross_analysis):\n",
    "    \"\"\"Create comprehensive visualizations for EDA insights\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"üìà COMPREHENSIVE DATA VISUALIZATIONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Set up the plotting environment\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    fig = plt.figure(figsize=(20, 24))\n",
    "    \n",
    "    # 1. Data Completeness Heatmap\n",
    "    plt.subplot(4, 2, 1)\n",
    "    missing_data = df.isnull()\n",
    "    sns.heatmap(missing_data.T, cbar=True, cmap='RdYlBu_r', \n",
    "                xticklabels=False, yticklabels=True)\n",
    "    plt.title('Data Completeness Heatmap\\n(Yellow = Missing, Blue = Present)', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Columns')\n",
    "    \n",
    "    # 2. Missing Data Percentage\n",
    "    plt.subplot(4, 2, 2)\n",
    "    missing_pct = (df.isnull().sum() / len(df)) * 100\n",
    "    missing_pct = missing_pct.sort_values(ascending=True)\n",
    "    colors = ['red' if x > 50 else 'orange' if x > 20 else 'green' for x in missing_pct]\n",
    "    missing_pct.plot(kind='barh', color=colors)\n",
    "    plt.title('Missing Data Percentage by Column', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Missing Percentage (%)')\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # 3. Qualifications Distribution (if available)\n",
    "    if qual_analysis:\n",
    "        plt.subplot(4, 2, 3)\n",
    "        first_qual_col = list(qual_analysis.keys())[0]\n",
    "        qual_counts = qual_analysis[first_qual_col]['counts'].head(10)\n",
    "        qual_counts.plot(kind='bar', color='skyblue', edgecolor='navy')\n",
    "        plt.title(f'Top 10 Qualifications Distribution\\n({first_qual_col})', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Qualifications')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 4. Work Types Distribution (if available)\n",
    "    if worktype_analysis:\n",
    "        plt.subplot(4, 2, 4)\n",
    "        first_worktype_col = list(worktype_analysis.keys())[0]\n",
    "        worktype_counts = worktype_analysis[first_worktype_col]['counts']\n",
    "        colors_wt = plt.cm.Set3(np.linspace(0, 1, len(worktype_counts)))\n",
    "        worktype_counts.plot(kind='pie', autopct='%1.1f%%', colors=colors_wt, startangle=90)\n",
    "        plt.title(f'Work Types Distribution\\n({first_worktype_col})', fontsize=14, fontweight='bold')\n",
    "        plt.ylabel('')\n",
    "    \n",
    "    # 5. Qualification Text Length Distribution (if available)\n",
    "    if qual_analysis:\n",
    "        plt.subplot(4, 2, 5)\n",
    "        first_qual_col = list(qual_analysis.keys())[0]\n",
    "        text_lengths = qual_analysis[first_qual_col]['text_lengths']\n",
    "        plt.hist(text_lengths, bins=30, color='lightcoral', edgecolor='darkred', alpha=0.7)\n",
    "        plt.title('Qualification Text Length Distribution', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Text Length (characters)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.axvline(text_lengths.mean(), color='red', linestyle='--', \n",
    "                   label=f'Mean: {text_lengths.mean():.1f}')\n",
    "        plt.legend()\n",
    "    \n",
    "    # 6. Work Type Text Length Distribution (if available)\n",
    "    if worktype_analysis:\n",
    "        plt.subplot(4, 2, 6)\n",
    "        first_worktype_col = list(worktype_analysis.keys())[0]\n",
    "        worktype_text_lengths = worktype_analysis[first_worktype_col]['text_lengths']\n",
    "        plt.hist(worktype_text_lengths, bins=20, color='lightgreen', edgecolor='darkgreen', alpha=0.7)\n",
    "        plt.title('Work Type Text Length Distribution', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Text Length (characters)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.axvline(worktype_text_lengths.mean(), color='red', linestyle='--',\n",
    "                   label=f'Mean: {worktype_text_lengths.mean():.1f}')\n",
    "        plt.legend()\n",
    "    \n",
    "    # 7. Data Completeness Overview\n",
    "    plt.subplot(4, 2, 7)\n",
    "    if cross_analysis:\n",
    "        completeness_data = [\n",
    "            cross_analysis['both_present_count'],\n",
    "            cross_analysis['qual_only_count'],\n",
    "            cross_analysis['worktype_only_count'],\n",
    "            cross_analysis['neither_count']\n",
    "        ]\n",
    "        labels = ['Both Present', 'Qual Only', 'WorkType Only', 'Neither']\n",
    "        colors_comp = ['green', 'orange', 'blue', 'red']\n",
    "        \n",
    "        plt.pie(completeness_data, labels=labels, autopct='%1.1f%%', \n",
    "                colors=colors_comp, startangle=90)\n",
    "        plt.title('Data Completeness Overview\\n(Qualification vs Work Type)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 8. Dataset Overview Statistics\n",
    "    plt.subplot(4, 2, 8)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # ---- FIX: compute safe values before f-string ----\n",
    "    qual_unique = f\"{qual_analysis[list(qual_analysis.keys())[0]]['unique_count']:,}\" if qual_analysis else \"N/A\"\n",
    "    worktype_unique = f\"{worktype_analysis[list(worktype_analysis.keys())[0]]['unique_count']:,}\" if worktype_analysis else \"N/A\"\n",
    "    overlap = f\"{cross_analysis['overlap_percentage']:.1f}%\" if cross_analysis else \"N/A\"\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "üìä DATASET OVERVIEW\n",
    "\n",
    "Total Records: {len(df):,}\n",
    "Total Columns: {len(df.columns)}\n",
    "Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\n",
    "\n",
    "üìã DATA QUALITY\n",
    "Complete Records: {(~df.isnull().any(axis=1)).sum():,}\n",
    "Records with Missing: {df.isnull().any(axis=1).sum():,}\n",
    "\n",
    "üéØ KEY INSIGHTS\n",
    "‚Ä¢ Unique Qualifications: {qual_unique}\n",
    "‚Ä¢ Unique Work Types: {worktype_unique}\n",
    "‚Ä¢ Data Overlap: {overlap}\n",
    "\"\"\"\n",
    "    \n",
    "    plt.text(0.1, 0.9, summary_text, transform=plt.gca().transAxes, \n",
    "             fontsize=12, verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('JobHunt Dataset - Comprehensive Exploratory Data Analysis', \n",
    "                 fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Comprehensive visualizations created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Loading dataset from: dataset/job_descriptions_100k_sample.csv\n",
      "‚úÖ Dataset loaded successfully!\n",
      "üìä Dataset shape: (100000, 23)\n",
      "üìã Columns: ['Job Id', 'Experience', 'Qualifications', 'Salary Range', 'location', 'Country', 'latitude', 'longitude', 'Work Type', 'Company Size', 'Job Posting Date', 'Preference', 'Contact Person', 'Contact', 'Job Title', 'Role', 'Job Portal', 'Job Description', 'Benefits', 'skills', 'Responsibilities', 'Company', 'Company Profile']\n",
      "\n",
      "üìã Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 23 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   Job Id            100000 non-null  int64  \n",
      " 1   Experience        100000 non-null  object \n",
      " 2   Qualifications    100000 non-null  object \n",
      " 3   Salary Range      100000 non-null  object \n",
      " 4   location          100000 non-null  object \n",
      " 5   Country           100000 non-null  object \n",
      " 6   latitude          100000 non-null  float64\n",
      " 7   longitude         100000 non-null  float64\n",
      " 8   Work Type         100000 non-null  object \n",
      " 9   Company Size      100000 non-null  int64  \n",
      " 10  Job Posting Date  100000 non-null  object \n",
      " 11  Preference        100000 non-null  object \n",
      " 12  Contact Person    100000 non-null  object \n",
      " 13  Contact           100000 non-null  object \n",
      " 14  Job Title         100000 non-null  object \n",
      " 15  Role              100000 non-null  object \n",
      " 16  Job Portal        100000 non-null  object \n",
      " 17  Job Description   100000 non-null  object \n",
      " 18  Benefits          100000 non-null  object \n",
      " 19  skills            100000 non-null  object \n",
      " 20  Responsibilities  100000 non-null  object \n",
      " 21  Company           100000 non-null  object \n",
      " 22  Company Profile   99687 non-null   object \n",
      "dtypes: float64(2), int64(2), object(19)\n",
      "memory usage: 17.5+ MB\n",
      "None\n",
      "\n",
      "üìä First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Id</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Qualifications</th>\n",
       "      <th>Salary Range</th>\n",
       "      <th>location</th>\n",
       "      <th>Country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Work Type</th>\n",
       "      <th>Company Size</th>\n",
       "      <th>Job Posting Date</th>\n",
       "      <th>Preference</th>\n",
       "      <th>Contact Person</th>\n",
       "      <th>Contact</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Role</th>\n",
       "      <th>Job Portal</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Benefits</th>\n",
       "      <th>skills</th>\n",
       "      <th>Responsibilities</th>\n",
       "      <th>Company</th>\n",
       "      <th>Company Profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731217710221434</td>\n",
       "      <td>1 to 9 Years</td>\n",
       "      <td>B.Com</td>\n",
       "      <td>$59K-$105K</td>\n",
       "      <td>Bissau</td>\n",
       "      <td>Guinea-Bissau</td>\n",
       "      <td>11.8037</td>\n",
       "      <td>-15.1804</td>\n",
       "      <td>Intern</td>\n",
       "      <td>56276</td>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Justin Turner</td>\n",
       "      <td>525.904.3659</td>\n",
       "      <td>IT Support Specialist</td>\n",
       "      <td>IT Systems Administrator</td>\n",
       "      <td>Jobs2Careers</td>\n",
       "      <td>IT Systems Administrators manage and maintain ...</td>\n",
       "      <td>{'Casual Dress Code, Social and Recreational A...</td>\n",
       "      <td>Network administration System and server maint...</td>\n",
       "      <td>Administer and maintain IT systems, servers, a...</td>\n",
       "      <td>Bharat Electronics Limited</td>\n",
       "      <td>{\"Sector\":\"Electronics\",\"Industry\":\"Electronic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117274981913427</td>\n",
       "      <td>2 to 14 Years</td>\n",
       "      <td>M.Com</td>\n",
       "      <td>$61K-$106K</td>\n",
       "      <td>Palikir</td>\n",
       "      <td>Micronesia, Fed. Sts.</td>\n",
       "      <td>7.4256</td>\n",
       "      <td>150.5508</td>\n",
       "      <td>Intern</td>\n",
       "      <td>73167</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>Male</td>\n",
       "      <td>Sarah Davis</td>\n",
       "      <td>(235)305-5348x40620</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>Java Backend Developer</td>\n",
       "      <td>Jobs2Careers</td>\n",
       "      <td>Java Backend Developers specialize in building...</td>\n",
       "      <td>{'Employee Assistance Programs (EAP), Tuition ...</td>\n",
       "      <td>Backend development RESTful APIs Database inte...</td>\n",
       "      <td>Develop server-side applications and APIs usin...</td>\n",
       "      <td>Autoliv</td>\n",
       "      <td>{\"Sector\":\"Automotive\",\"Industry\":\"Motor Vehic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1223957703158372</td>\n",
       "      <td>5 to 11 Years</td>\n",
       "      <td>MBA</td>\n",
       "      <td>$58K-$121K</td>\n",
       "      <td>Mexico City</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>23.6345</td>\n",
       "      <td>-102.5528</td>\n",
       "      <td>Intern</td>\n",
       "      <td>85065</td>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>Male</td>\n",
       "      <td>Rachel Kim</td>\n",
       "      <td>+1-673-276-6953x56364</td>\n",
       "      <td>Digital Marketing Specialist</td>\n",
       "      <td>Email Marketing Specialist</td>\n",
       "      <td>Jobs2Careers</td>\n",
       "      <td>Email Marketing Specialists design and execute...</td>\n",
       "      <td>{'Childcare Assistance, Paid Time Off (PTO), R...</td>\n",
       "      <td>Email marketing platforms (e.g., Mailchimp, Co...</td>\n",
       "      <td>Plan and execute email marketing campaigns, in...</td>\n",
       "      <td>Titan Company</td>\n",
       "      <td>{\"Sector\":\"Consumer Goods\",\"Industry\":\"Jewelry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2820360512579168</td>\n",
       "      <td>4 to 8 Years</td>\n",
       "      <td>MCA</td>\n",
       "      <td>$62K-$102K</td>\n",
       "      <td>Apia</td>\n",
       "      <td>Samoa</td>\n",
       "      <td>-13.7590</td>\n",
       "      <td>-172.1046</td>\n",
       "      <td>Intern</td>\n",
       "      <td>78831</td>\n",
       "      <td>2023-03-18</td>\n",
       "      <td>Male</td>\n",
       "      <td>Susan Navarro</td>\n",
       "      <td>+1-912-629-7264x430</td>\n",
       "      <td>Physician Assistant</td>\n",
       "      <td>Surgical Physician Assistant</td>\n",
       "      <td>Jobs2Careers</td>\n",
       "      <td>Assist surgeons in the operating room, perform...</td>\n",
       "      <td>{'Life and Disability Insurance, Stock Options...</td>\n",
       "      <td>Surgical procedures and techniques Operating r...</td>\n",
       "      <td>Assist surgeons in the operating room, includi...</td>\n",
       "      <td>Adidas AG</td>\n",
       "      <td>{\"Sector\":\"Apparel and Footwear\",\"Industry\":\"A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2675139962258067</td>\n",
       "      <td>0 to 14 Years</td>\n",
       "      <td>B.Tech</td>\n",
       "      <td>$59K-$83K</td>\n",
       "      <td>Antananarivo</td>\n",
       "      <td>Madagascar</td>\n",
       "      <td>-18.8792</td>\n",
       "      <td>46.8451</td>\n",
       "      <td>Intern</td>\n",
       "      <td>55698</td>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>Male</td>\n",
       "      <td>Darrell Freeman</td>\n",
       "      <td>389.243.9156x241</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>ETL Developer</td>\n",
       "      <td>Jobs2Careers</td>\n",
       "      <td>An ETL Developer specializes in designing and ...</td>\n",
       "      <td>{'Transportation Benefits, Professional Develo...</td>\n",
       "      <td>ETL (Extract, Transform, Load) processes Data ...</td>\n",
       "      <td>Extract, transform, and load (ETL) data from v...</td>\n",
       "      <td>Devon Energy</td>\n",
       "      <td>{\"Sector\":\"Energy\",\"Industry\":\"Mining, Crude-O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Job Id     Experience Qualifications Salary Range      location  \\\n",
       "0   731217710221434   1 to 9 Years          B.Com   $59K-$105K        Bissau   \n",
       "1   117274981913427  2 to 14 Years          M.Com   $61K-$106K       Palikir   \n",
       "2  1223957703158372  5 to 11 Years            MBA   $58K-$121K   Mexico City   \n",
       "3  2820360512579168   4 to 8 Years            MCA   $62K-$102K          Apia   \n",
       "4  2675139962258067  0 to 14 Years         B.Tech    $59K-$83K  Antananarivo   \n",
       "\n",
       "                 Country  latitude  longitude Work Type  Company Size  \\\n",
       "0          Guinea-Bissau   11.8037   -15.1804    Intern         56276   \n",
       "1  Micronesia, Fed. Sts.    7.4256   150.5508    Intern         73167   \n",
       "2                 Mexico   23.6345  -102.5528    Intern         85065   \n",
       "3                  Samoa  -13.7590  -172.1046    Intern         78831   \n",
       "4             Madagascar  -18.8792    46.8451    Intern         55698   \n",
       "\n",
       "  Job Posting Date Preference   Contact Person                Contact  \\\n",
       "0       2023-04-24       Male    Justin Turner           525.904.3659   \n",
       "1       2022-03-21       Male      Sarah Davis    (235)305-5348x40620   \n",
       "2       2023-04-07       Male       Rachel Kim  +1-673-276-6953x56364   \n",
       "3       2023-03-18       Male    Susan Navarro    +1-912-629-7264x430   \n",
       "4       2022-04-05       Male  Darrell Freeman       389.243.9156x241   \n",
       "\n",
       "                      Job Title                          Role    Job Portal  \\\n",
       "0         IT Support Specialist      IT Systems Administrator  Jobs2Careers   \n",
       "1                Java Developer        Java Backend Developer  Jobs2Careers   \n",
       "2  Digital Marketing Specialist    Email Marketing Specialist  Jobs2Careers   \n",
       "3           Physician Assistant  Surgical Physician Assistant  Jobs2Careers   \n",
       "4                 Data Engineer                 ETL Developer  Jobs2Careers   \n",
       "\n",
       "                                     Job Description  \\\n",
       "0  IT Systems Administrators manage and maintain ...   \n",
       "1  Java Backend Developers specialize in building...   \n",
       "2  Email Marketing Specialists design and execute...   \n",
       "3  Assist surgeons in the operating room, perform...   \n",
       "4  An ETL Developer specializes in designing and ...   \n",
       "\n",
       "                                            Benefits  \\\n",
       "0  {'Casual Dress Code, Social and Recreational A...   \n",
       "1  {'Employee Assistance Programs (EAP), Tuition ...   \n",
       "2  {'Childcare Assistance, Paid Time Off (PTO), R...   \n",
       "3  {'Life and Disability Insurance, Stock Options...   \n",
       "4  {'Transportation Benefits, Professional Develo...   \n",
       "\n",
       "                                              skills  \\\n",
       "0  Network administration System and server maint...   \n",
       "1  Backend development RESTful APIs Database inte...   \n",
       "2  Email marketing platforms (e.g., Mailchimp, Co...   \n",
       "3  Surgical procedures and techniques Operating r...   \n",
       "4  ETL (Extract, Transform, Load) processes Data ...   \n",
       "\n",
       "                                    Responsibilities  \\\n",
       "0  Administer and maintain IT systems, servers, a...   \n",
       "1  Develop server-side applications and APIs usin...   \n",
       "2  Plan and execute email marketing campaigns, in...   \n",
       "3  Assist surgeons in the operating room, includi...   \n",
       "4  Extract, transform, and load (ETL) data from v...   \n",
       "\n",
       "                      Company  \\\n",
       "0  Bharat Electronics Limited   \n",
       "1                     Autoliv   \n",
       "2               Titan Company   \n",
       "3                   Adidas AG   \n",
       "4                Devon Energy   \n",
       "\n",
       "                                     Company Profile  \n",
       "0  {\"Sector\":\"Electronics\",\"Industry\":\"Electronic...  \n",
       "1  {\"Sector\":\"Automotive\",\"Industry\":\"Motor Vehic...  \n",
       "2  {\"Sector\":\"Consumer Goods\",\"Industry\":\"Jewelry...  \n",
       "3  {\"Sector\":\"Apparel and Footwear\",\"Industry\":\"A...  \n",
       "4  {\"Sector\":\"Energy\",\"Industry\":\"Mining, Crude-O...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to load the actual dataset\n",
    "dataset_path = Path('./dataset/job_descriptions_100k_sample.csv')\n",
    "\n",
    "if dataset_path.exists():\n",
    "    print(f'üìÅ Loading dataset from: {dataset_path}')\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    print(f'‚úÖ Dataset loaded successfully!')\n",
    "    print(f'üìä Dataset shape: {df.shape}')\n",
    "    print(f'üìã Columns: {list(df.columns)}')\n",
    "else:\n",
    "    print('‚ö†Ô∏è Dataset not found. Creating sample data for demonstration...')\n",
    "    \n",
    "\n",
    "# Display basic info\n",
    "print('\\nüìã Dataset Info:')\n",
    "print(df.info())\n",
    "print('\\nüìä First 5 rows:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Individual Module Testing\n",
    "\n",
    "Let's test each feature engineering module individually to understand their functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Qualifications Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéì QUALIFICATIONS PROCESSING\n",
      "==================================================\n",
      "Individual classification examples:\n",
      "  Bachelor of Science ‚Üí Bachelor\n",
      "  Master of Arts ‚Üí Master\n",
      "  PhD in Computer Science ‚Üí PhD\n",
      "  High School Diploma ‚Üí Other\n",
      "  None ‚Üí Other\n",
      "\n",
      "Processing qualifications from dataset:\n",
      "Generated features: ['qualification_category', 'is_bachelor', 'is_master', 'is_phd', 'has_qualification']\n",
      "\n",
      "Qualification features preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qualification_category</th>\n",
       "      <th>is_bachelor</th>\n",
       "      <th>is_master</th>\n",
       "      <th>is_phd</th>\n",
       "      <th>has_qualification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Master</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Master</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Master</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bachelor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qualification_category  is_bachelor  is_master  is_phd  has_qualification\n",
       "0               Bachelor            1          0       0                  1\n",
       "1                 Master            0          1       0                  1\n",
       "2                 Master            0          1       0                  1\n",
       "3                 Master            0          1       0                  1\n",
       "4               Bachelor            1          0       0                  1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('üéì QUALIFICATIONS PROCESSING')\n",
    "print('=' * 50)\n",
    "\n",
    "# Test individual classification\n",
    "test_qualifications = [\n",
    "    'Bachelor of Science',\n",
    "    'Master of Arts',\n",
    "    'PhD in Computer Science',\n",
    "    'High School Diploma',\n",
    "    None\n",
    "]\n",
    "\n",
    "print('Individual classification examples:')\n",
    "for qual in test_qualifications:\n",
    "    category = classify_qualification(qual)\n",
    "    print(f'  {qual} ‚Üí {category}')\n",
    "\n",
    "# Process full series\n",
    "print('\\nProcessing qualifications from dataset:')\n",
    "qual_features = process_qualifications(df['Qualifications'])\n",
    "print(f'Generated features: {list(qual_features.columns)}')\n",
    "print('\\nQualification features preview:')\n",
    "qual_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Work Type Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üíº WORK TYPE PROCESSING')\n",
    "print('=' * 50)\n",
    "\n",
    "# Test individual standardization\n",
    "test_work_types = [\n",
    "    'Full Time',\n",
    "    'Contract',\n",
    "    'Part-time',\n",
    "    'Internship',\n",
    "    'Freelance'\n",
    "]\n",
    "\n",
    "print('Individual standardization examples:')\n",
    "for wt in test_work_types:\n",
    "    standardized = standardize_work_type(wt)\n",
    "    print(f'  {wt} ‚Üí {standardized}')\n",
    "\n",
    "# Process full series\n",
    "print('\\nProcessing work types from dataset:')\n",
    "worktype_features = process_work_types(df['Work Type'])\n",
    "print(f'Generated features: {list(worktype_features.columns)}')\n",
    "print('\\nWork type features preview:')\n",
    "worktype_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Experience Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üìà EXPERIENCE PROCESSING')\n",
    "print('=' * 50)\n",
    "\n",
    "# Test individual parsing\n",
    "test_experiences = [\n",
    "    '1 to 9 Years',\n",
    "    '5+ years',\n",
    "    'Entry Level',\n",
    "    'Senior',\n",
    "    '3-5 years'\n",
    "]\n",
    "\n",
    "print('Individual parsing examples:')\n",
    "for exp in test_experiences:\n",
    "    min_exp, max_exp, mid_exp = parse_experience_range(exp)\n",
    "    print(f'  {exp} ‚Üí min: {min_exp}, max: {max_exp}, mid: {mid_exp}')\n",
    "\n",
    "# Process full series\n",
    "print('\\nProcessing experience from dataset:')\n",
    "exp_features = process_experience(df['Experience'])\n",
    "print(f'Generated features: {list(exp_features.columns)}')\n",
    "print('\\nExperience features preview:')\n",
    "exp_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Salary Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üí∞ SALARY PROCESSING')\n",
    "print('=' * 50)\n",
    "\n",
    "# Test individual parsing\n",
    "test_salaries = [\n",
    "    '$50,000 - $80,000',\n",
    "    '60K+',\n",
    "    '75000',\n",
    "    '$90K-$120K',\n",
    "    '‚Çπ5,00,000 per annum'\n",
    "]\n",
    "\n",
    "print('Individual parsing examples:')\n",
    "for sal in test_salaries:\n",
    "    min_sal, max_sal, mid_sal = parse_salary_range(sal)\n",
    "    print(f'  {sal} ‚Üí min: {min_sal}, max: {max_sal}, mid: {mid_sal}')\n",
    "\n",
    "# Process full series\n",
    "print('\\nProcessing salary from dataset:')\n",
    "salary_features = process_salary(df['Salary'])\n",
    "print(f'Generated features: {list(salary_features.columns)}')\n",
    "print('\\nSalary features preview:')\n",
    "salary_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üìù TEXT PROCESSING')\n",
    "print('=' * 50)\n",
    "\n",
    "# Test individual text combination\n",
    "print('Individual text combination examples:')\n",
    "for i in range(3):\n",
    "    role = df['Role'].iloc[i]\n",
    "    title = df['Job Title'].iloc[i]\n",
    "    skills = df['Skills'].iloc[i]\n",
    "    combined = clean_and_combine_text(role, title, skills)\n",
    "    print(f'  Role: {role}')\n",
    "    print(f'  Title: {title}')\n",
    "    print(f'  Skills: {skills}')\n",
    "    print(f'  Combined: {combined}')\n",
    "    print()\n",
    "\n",
    "# Process full dataset\n",
    "print('Processing text features from dataset:')\n",
    "text_features = process_text_features(df, 'Role', 'Job Title', 'Skills')\n",
    "print(f'Generated features: {list(text_features.columns)}')\n",
    "print('\\nText features preview:')\n",
    "text_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Complete Pipeline Demonstration\n",
    "\n",
    "Now let's use the complete `FeatureEngineeringPipeline` to process all features at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üèóÔ∏è COMPLETE FEATURE ENGINEERING PIPELINE')\n",
    "print('=' * 60)\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipeline = FeatureEngineeringPipeline(\n",
    "    qualification_col='Qualifications',\n",
    "    work_type_col='Work Type',\n",
    "    experience_col='Experience',\n",
    "    salary_col='Salary',\n",
    "    role_col='Role',\n",
    "    job_title_col='Job Title',\n",
    "    skills_col='Skills'\n",
    ")\n",
    "\n",
    "print('‚úÖ Pipeline initialized successfully!')\n",
    "print('\\nüîÑ Running complete transformation...')\n",
    "\n",
    "# Transform the data\n",
    "transformed_df = pipeline.transform(df, include_stats=True, verbose=True)\n",
    "\n",
    "print(f'\\nüìä Transformation Results:')\n",
    "print(f'  Original shape: {df.shape}')\n",
    "print(f'  Transformed shape: {transformed_df.shape}')\n",
    "print(f'  Features added: {len(pipeline.get_feature_columns())}')\n",
    "\n",
    "print('\\nüéØ Generated Feature Columns:')\n",
    "for i, col in enumerate(pipeline.get_feature_columns(), 1):\n",
    "    print(f'  {i:2d}. {col}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display transformation summary\n",
    "print('\\nüìà TRANSFORMATION SUMMARY')\n",
    "print('=' * 60)\n",
    "pipeline.print_transformation_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of transformed data\n",
    "print('\\nüìã TRANSFORMED DATA PREVIEW')\n",
    "print('=' * 60)\n",
    "\n",
    "# Show only the new features\n",
    "feature_columns = pipeline.get_feature_columns()\n",
    "print(f'Showing {len(feature_columns)} engineered features:')\n",
    "transformed_df[feature_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for the engineered features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Feature Engineering Results - Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Qualification Distribution\n",
    "if 'qualification_category' in transformed_df.columns:\n",
    "    qual_counts = transformed_df['qualification_category'].value_counts()\n",
    "    axes[0, 0].pie(qual_counts.values, labels=qual_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[0, 0].set_title('Qualification Categories')\n",
    "\n",
    "# 2. Work Type Distribution\n",
    "if 'work_type_category' in transformed_df.columns:\n",
    "    work_counts = transformed_df['work_type_category'].value_counts()\n",
    "    axes[0, 1].bar(work_counts.index, work_counts.values, color='skyblue')\n",
    "    axes[0, 1].set_title('Work Type Distribution')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Experience Distribution\n",
    "if 'experience_mid' in transformed_df.columns:\n",
    "    exp_data = transformed_df['experience_mid'].dropna()\n",
    "    if len(exp_data) > 0:\n",
    "        axes[0, 2].hist(exp_data, bins=10, color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "        axes[0, 2].set_title('Experience Distribution (Years)')\n",
    "        axes[0, 2].set_xlabel('Years of Experience')\n",
    "        axes[0, 2].set_ylabel('Frequency')\n",
    "\n",
    "# 4. Salary Distribution\n",
    "if 'salary_mid' in transformed_df.columns:\n",
    "    salary_data = transformed_df['salary_mid'].dropna()\n",
    "    if len(salary_data) > 0:\n",
    "        axes[1, 0].hist(salary_data, bins=10, color='gold', alpha=0.7, edgecolor='black')\n",
    "        axes[1, 0].set_title('Salary Distribution')\n",
    "        axes[1, 0].set_xlabel('Salary ($)')\n",
    "        axes[1, 0].set_ylabel('Frequency')\n",
    "        # Format x-axis to show salary in K format\n",
    "        axes[1, 0].xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "\n",
    "# 5. Feature Completeness\n",
    "feature_cols = pipeline.get_feature_columns()\n",
    "completeness = {}\n",
    "for col in feature_cols[:10]:  # Show top 10 features\n",
    "    if col in transformed_df.columns:\n",
    "        completeness[col] = (transformed_df[col].notna().sum() / len(transformed_df)) * 100\n",
    "\n",
    "if completeness:\n",
    "    comp_df = pd.Series(completeness).sort_values(ascending=True)\n",
    "    axes[1, 1].barh(range(len(comp_df)), comp_df.values, color='coral')\n",
    "    axes[1, 1].set_yticks(range(len(comp_df)))\n",
    "    axes[1, 1].set_yticklabels([col.replace('_', ' ').title() for col in comp_df.index])\n",
    "    axes[1, 1].set_title('Feature Completeness (%)')\n",
    "    axes[1, 1].set_xlabel('Completeness (%)')\n",
    "\n",
    "# 6. Correlation Heatmap (for numerical features)\n",
    "numerical_features = []\n",
    "for col in feature_cols:\n",
    "    if col in transformed_df.columns and transformed_df[col].dtype in ['int64', 'float64']:\n",
    "        numerical_features.append(col)\n",
    "\n",
    "if len(numerical_features) > 1:\n",
    "    corr_matrix = transformed_df[numerical_features].corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, ax=axes[1, 2], cbar_kws={'shrink': 0.8})\n",
    "    axes[1, 2].set_title('Feature Correlation Matrix')\n",
    "else:\n",
    "    axes[1, 2].text(0.5, 0.5, 'Not enough numerical\\nfeatures for correlation', \n",
    "                    ha='center', va='center', transform=axes[1, 2].transAxes)\n",
    "    axes[1, 2].set_title('Feature Correlation Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üîç FEATURE QUALITY ASSESSMENT')\n",
    "print('=' * 60)\n",
    "\n",
    "feature_cols = pipeline.get_feature_columns()\n",
    "quality_report = []\n",
    "\n",
    "for col in feature_cols:\n",
    "    if col in transformed_df.columns:\n",
    "        # Calculate quality metrics\n",
    "        total_count = len(transformed_df)\n",
    "        non_null_count = transformed_df[col].notna().sum()\n",
    "        completeness = (non_null_count / total_count) * 100\n",
    "        \n",
    "        # Uniqueness\n",
    "        unique_count = transformed_df[col].nunique()\n",
    "        uniqueness = (unique_count / non_null_count) * 100 if non_null_count > 0 else 0\n",
    "        \n",
    "        # Variance (for numerical columns)\n",
    "        variance = 'N/A'\n",
    "        if transformed_df[col].dtype in ['int64', 'float64']:\n",
    "            var_val = transformed_df[col].var()\n",
    "            variance = f'{var_val:.2f}' if pd.notna(var_val) else 'N/A'\n",
    "        \n",
    "        quality_report.append({\n",
    "            'Feature': col,\n",
    "            'Type': str(transformed_df[col].dtype),\n",
    "            'Completeness (%)': f'{completeness:.1f}',\n",
    "            'Unique Values': unique_count,\n",
    "            'Uniqueness (%)': f'{uniqueness:.1f}',\n",
    "            'Variance': variance\n",
    "        })\n",
    "\n",
    "# Create quality report DataFrame\n",
    "quality_df = pd.DataFrame(quality_report)\n",
    "print('Feature Quality Report:')\n",
    "print(quality_df.to_string(index=False))\n",
    "\n",
    "# Identify high-quality features\n",
    "print('\\nüåü HIGH-QUALITY FEATURES (>80% complete, >10% unique):')\n",
    "high_quality = []\n",
    "for _, row in quality_df.iterrows():\n",
    "    completeness = float(row['Completeness (%)'])\n",
    "    uniqueness = float(row['Uniqueness (%)'])\n",
    "    if completeness > 80 and uniqueness > 10:\n",
    "        high_quality.append(row['Feature'])\n",
    "        print(f'  ‚úÖ {row[\"Feature\"]} (Complete: {row[\"Completeness (%)\"]}, Unique: {row[\"Uniqueness (%)\"]})\n",
    "\n",
    "print(f'\\nüìä Summary: {len(high_quality)}/{len(feature_cols)} features meet high-quality criteria')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Processed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üíæ EXPORTING PROCESSED FEATURES')\n",
    "print('=' * 60)\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('feature_engineering_output')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 1. Save complete dataset with all features\n",
    "complete_path = output_dir / 'complete_dataset_with_features.csv'\n",
    "transformed_df.to_csv(complete_path, index=False)\n",
    "print(f'‚úÖ Complete dataset saved: {complete_path}')\n",
    "\n",
    "# 2. Save only engineered features\n",
    "features_only_path = output_dir / 'engineered_features_only.csv'\n",
    "pipeline.save_features(transformed_df, features_only_path, features_only=True)\n",
    "\n",
    "# 3. Save high-quality features only\n",
    "if high_quality:\n",
    "    hq_features_path = output_dir / 'high_quality_features.csv'\n",
    "    transformed_df[high_quality].to_csv(hq_features_path, index=False)\n",
    "    print(f'‚úÖ High-quality features saved: {hq_features_path}')\n",
    "\n",
    "# 4. Save feature metadata\n",
    "metadata_path = output_dir / 'feature_metadata.csv'\n",
    "quality_df.to_csv(metadata_path, index=False)\n",
    "print(f'‚úÖ Feature metadata saved: {metadata_path}')\n",
    "\n",
    "# 5. Save transformation statistics\n",
    "stats = pipeline.get_transformation_stats()\n",
    "stats_path = output_dir / 'transformation_statistics.txt'\n",
    "with open(stats_path, 'w') as f:\n",
    "    f.write('FEATURE ENGINEERING TRANSFORMATION STATISTICS\\n')\n",
    "    f.write('=' * 60 + '\\n\\n')\n",
    "    for transform_name, transform_stats in stats.items():\n",
    "        f.write(f'{transform_name.upper()} TRANSFORMATION:\\n')\n",
    "        f.write('-' * 30 + '\\n')\n",
    "        for key, value in transform_stats.items():\n",
    "            f.write(f'{key}: {value}\\n')\n",
    "        f.write('\\n')\n",
    "print(f'‚úÖ Transformation statistics saved: {stats_path}')\n",
    "\n",
    "print(f'\\nüìÅ All outputs saved to: {output_dir.absolute()}')\n",
    "print(f'üìä Files created:')\n",
    "for file_path in output_dir.glob('*'):\n",
    "    size_kb = file_path.stat().st_size / 1024\n",
    "    print(f'  - {file_path.name} ({size_kb:.1f} KB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps\n",
    "\n",
    "### üéØ **What We Accomplished:**\n",
    "\n",
    "1. **‚úÖ Individual Module Testing**: Tested each feature engineering component separately\n",
    "2. **‚úÖ Complete Pipeline**: Demonstrated the full `FeatureEngineeringPipeline`\n",
    "3. **‚úÖ Feature Analysis**: Analyzed feature quality and distributions\n",
    "4. **‚úÖ Visualization**: Created comprehensive plots for feature understanding\n",
    "5. **‚úÖ Quality Assessment**: Identified high-quality features for modeling\n",
    "6. **‚úÖ Export**: Saved processed features and metadata for future use\n",
    "\n",
    "### üöÄ **Next Steps:**\n",
    "\n",
    "1. **Model Training**: Use the engineered features for machine learning models\n",
    "2. **Feature Selection**: Apply feature selection techniques to identify the most important features\n",
    "3. **Pipeline Integration**: Integrate this pipeline into your production workflow\n",
    "4. **Monitoring**: Set up monitoring for feature drift and quality degradation\n",
    "5. **Optimization**: Fine-tune feature engineering based on model performance\n",
    "\n",
    "### üìö **Key Takeaways:**\n",
    "\n",
    "- The feature engineering pipeline is **modular** and **reusable**\n",
    "- Each transformation handles **missing data** gracefully\n",
    "- The pipeline provides **comprehensive statistics** for monitoring\n",
    "- Features are **well-documented** and **interpretable**\n",
    "- The system is **production-ready** with proper error handling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
